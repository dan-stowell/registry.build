<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><div class="markdown-heading" dir="auto"><h1 class="heading-element" dir="auto">About the <em>Modern C++ Kafka API</em></h1><a id="user-content-about-the-modern-c-kafka-api" class="anchor" aria-label="Permalink: About the Modern C++ Kafka API" href="#about-the-modern-c-kafka-api"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/2de09e70c4625f7d2688d6ea22e869d045e4586582c6eb6f06d6f5de2dde4982/68747470733a2f2f62616467656e2e6e65742f62616467652f4c6966656379636c652f4163746976652f677265656e"><img src="https://camo.githubusercontent.com/2de09e70c4625f7d2688d6ea22e869d045e4586582c6eb6f06d6f5de2dde4982/68747470733a2f2f62616467656e2e6e65742f62616467652f4c6966656379636c652f4163746976652f677265656e" alt="Lifecycle Active" data-canonical-src="https://badgen.net/badge/Lifecycle/Active/green" style="max-width: 100%;"></a></p>
<p dir="auto">The <a href="http://opensource.morganstanley.com/modern-cpp-kafka/doxygen/annotated.html" rel="nofollow">modern-cpp-kafka API</a> is a layer of <em><strong>C++</strong></em> wrapper based on <a href="https://github.com/confluentinc/librdkafka">librdkafka</a> (the <em><strong>C</strong></em> part only), with high quality, but more friendly to users.</p>
<ul dir="auto">
<li>By now, <a href="https://github.com/morganstanley/modern-cpp-kafka">modern-cpp-kafka</a> is compatible with <a href="https://github.com/confluentinc/librdkafka/releases/tag/v2.4.0">librdkafka v2.4.0</a>.</li>
</ul>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="KAFKA is a registered trademark of The Apache Software Foundation and
has been licensed for use by modern-cpp-kafka. modern-cpp-kafka has no
affiliation with and is not endorsed by The Apache Software Foundation."><pre class="notranslate"><code>KAFKA is a registered trademark of The Apache Software Foundation and
has been licensed for use by modern-cpp-kafka. modern-cpp-kafka has no
affiliation with and is not endorsed by The Apache Software Foundation.
</code></pre></div>
<div class="markdown-heading" dir="auto"><h1 class="heading-element" dir="auto">Why it's here</h1><a id="user-content-why-its-here" class="anchor" aria-label="Permalink: Why it's here" href="#why-its-here"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The <em><strong>librdkafka</strong></em> is a robust high performance C/C++ library, widely used and well maintained.</p>
<p dir="auto">Unfortunately, to maintain <em><strong>C++98</strong></em> compatibility, the <em><strong>C++</strong></em> interface of <em><strong>librdkafka</strong></em> is not quite object-oriented or user-friendly.</p>
<p dir="auto">Since C++ is evolving quickly, we want to take advantage of new C++ features, thus making life easier for developers. And this led us to create a new C++ API for Kafka clients.</p>
<p dir="auto">Eventually, we worked out the <em><strong>modern-cpp-kafka</strong></em>, -- a <em><strong>header-only</strong></em> library that uses idiomatic <em><strong>C++</strong></em> features to provide a safe, efficient and easy to use way of producing and consuming Kafka messages.</p>
<div class="markdown-heading" dir="auto"><h1 class="heading-element" dir="auto">Features</h1><a id="user-content-features" class="anchor" aria-label="Permalink: Features" href="#features"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto"><strong>Header-only</strong></p>
<ul dir="auto">
<li>Easy to deploy, and no extra library required to link</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Ease of Use</strong></p>
<ul dir="auto">
<li>
<p dir="auto">Interface/Naming matches the Java API</p>
</li>
<li>
<p dir="auto">Object-oriented</p>
</li>
<li>
<p dir="auto">RAII is used for lifetime management</p>
</li>
<li>
<p dir="auto"><em><strong>librdkafka</strong></em>'s polling and queue management is now hidden</p>
</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Robust</strong></p>
<ul dir="auto">
<li>
<p dir="auto">Verified with kinds of test cases, which cover many abnormal scenarios (edge cases)</p>
<ul dir="auto">
<li>
<p dir="auto">Stability test with unstable brokers</p>
</li>
<li>
<p dir="auto">Memory leak check for failed client with in-flight messages</p>
</li>
<li>
<p dir="auto">Client failure and taking over, etc.</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Efficient</strong></p>
<ul dir="auto">
<li>
<p dir="auto">No extra performance cost (No deep copy introduced internally)</p>
</li>
<li>
<p dir="auto">Much better (2~4 times throughput) performance result than those native language (Java/Scala) implementation, in most commonly used cases (message size: 256 B ~ 2 KB)</p>
</li>
</ul>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h1 class="heading-element" dir="auto">Installation / Requirements</h1><a id="user-content-installation--requirements" class="anchor" aria-label="Permalink: Installation / Requirements" href="#installation--requirements"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">Just include the <a href="https://github.com/morganstanley/modern-cpp-kafka/tree/main/include/kafka"><code>include/kafka</code></a> directory for your project</p>
</li>
<li>
<p dir="auto">The compiler should support <em><strong>C++17</strong></em></p>
<ul dir="auto">
<li>
<p dir="auto">Or, <em><strong>C++14</strong></em>, but with pre-requirements</p>
<ul dir="auto">
<li>
<p dir="auto">Need <em><strong>boost</strong></em> headers (for <code>boost::optional</code>)</p>
</li>
<li>
<p dir="auto">For <em><strong>GCC</strong></em> compiler, it needs optimization options (e.g. <code>-O2</code>)</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p dir="auto">Dependencies</p>
<ul dir="auto">
<li>
<p dir="auto"><a href="https://github.com/confluentinc/librdkafka"><strong>librdkafka</strong></a> headers and library (only the C part)</p>
<ul dir="auto">
<li>Also see the <a href="https://github.com/confluentinc/librdkafka#requirements">requirements from <strong>librdkafka</strong></a></li>
</ul>
</li>
<li>
<p dir="auto"><a href="https://github.com/Tencent/rapidjson"><strong>rapidjson</strong></a> headers: only required by <code>addons/KafkaMetrics.h</code></p>
</li>
</ul>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h1 class="heading-element" dir="auto">User Manual</h1><a id="user-content-user-manual" class="anchor" aria-label="Permalink: User Manual" href="#user-manual"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto"><a href="https://github.com/morganstanley/modern-cpp-kafka/releases">Release Notes</a></p>
</li>
<li>
<p dir="auto"><a href="http://opensource.morganstanley.com/modern-cpp-kafka/doxygen/annotated.html" rel="nofollow">Class List</a></p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h2 class="heading-element" dir="auto">Properties</h2><a id="user-content-properties" class="anchor" aria-label="Permalink: Properties" href="#properties"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><a href="http://opensource.morganstanley.com/modern-cpp-kafka/doxygen/classKAFKA__API_1_1Properties.html" rel="nofollow">kafka::Properties Class Reference</a></p>
<ul dir="auto">
<li>
<p dir="auto">It is a map which contains all configuration info needed to initialize a Kafka client, and it's <strong>the only</strong> parameter needed for a constructor.</p>
</li>
<li>
<p dir="auto">The configuration items are <em><strong>key-value</strong></em> pairs, -- the type of <em><strong>key</strong></em> is always <code>std::string</code>, while the type for a <em><strong>value</strong></em> could be one of the followings</p>
<ul dir="auto">
<li>
<p dir="auto"><code>std::string</code></p>
<ul dir="auto">
<li>
<p dir="auto">Most items are identical with <a href="https://github.com/confluentinc/librdkafka/blob/master/CONFIGURATION.md"><strong>librdkafka</strong> configuration</a></p>
</li>
<li>
<p dir="auto">But with exceptions</p>
<ul dir="auto">
<li>
<p dir="auto">Default value changes</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Key String</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>log_level</code></td>
<td><code>5</code></td>
<td>Default was <code>6</code> from <strong>librdkafka</strong></td>
</tr>
<tr>
<td><code>client.id</code></td>
<td>random string</td>
<td>No default from <strong>librdkafka</strong></td>
</tr>
<tr>
<td><code>group.id</code></td>
<td>random string</td>
<td>(for <code>KafkaConsumer</code> only) No default from <strong>librdkafka</strong></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</li>
<li>
<p dir="auto">Additional options</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Key String</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>enable.manual.events.poll</code></td>
<td><code>false</code></td>
<td>To poll the (offset-commit/message-delivery callback) events manually</td>
</tr>
<tr>
<td><code>max.poll.records</code></td>
<td><code>500</code></td>
<td>(for <code>KafkaConsumer</code> only) The maximum number of records that a single call to <code>poll()</code> would return</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</li>
<li>
<p dir="auto">Ignored options</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Key String</th>
<th>Explanation</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>enable.auto.offset.store</code></td>
<td><em><strong>modern-cpp-kafka</strong></em> will save the offsets in its own way</td>
</tr>
<tr>
<td><code>auto.commit.interval.ms</code></td>
<td><em><strong>modern-cpp-kafka</strong></em> will only commit the offsets within each <code>poll()</code> operation</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p dir="auto"><code>std::function&lt;...&gt;</code></p>
<ul dir="auto">
<li>For kinds of callbacks</li>
</ul>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Key String</th>
<th>Value Type</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>log_cb</code></td>
<td><code>LogCallback</code> (<code>std::function&lt;void(int, const char*, int, const char* msg)&gt;</code>)</td>
</tr>
<tr>
<td><code>error_cb</code></td>
<td><code>ErrorCallback</code> (<code>std::function&lt;void(const Error&amp;)&gt;</code>)</td>
</tr>
<tr>
<td><code>stats_cb</code></td>
<td><code>StatsCallback</code> (<code>std::function&lt;void(const std::string&amp;)&gt;</code>)</td>
</tr>
<tr>
<td><code>oauthbearer_token_refresh_cb</code></td>
<td><code>OauthbearerTokenRefreshCallback</code> (<code>std::function&lt;SaslOauthbearerToken(const std::string&amp;)&gt;</code>)</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</li>
<li>
<p dir="auto"><code>Interceptors</code></p>
<ul dir="auto">
<li>To intercept thread start/exit events, etc.</li>
</ul>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Key String</th>
<th>Value Type</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>interceptors</code></td>
<td><code>Interceptors</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</li>
</ul>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">Examples</h3><a id="user-content-examples" class="anchor" aria-label="Permalink: Examples" href="#examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="std::string brokers = &quot;192.168.0.1:9092,192.168.0.2:9092,192.168.0.3:9092&quot;;

kafka::Properties props ({
    {&quot;bootstrap.servers&quot;,  {brokers}},
    {&quot;enable.idempotence&quot;, {&quot;true&quot;}},
});"><pre class="notranslate"><code>std::string brokers = "192.168.0.1:9092,192.168.0.2:9092,192.168.0.3:9092";

kafka::Properties props ({
    {"bootstrap.servers",  {brokers}},
    {"enable.idempotence", {"true"}},
});
</code></pre></div>
</li>
<li>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="kafka::Properties props;
props.put(&quot;bootstrap.servers&quot;, brokers);
props.put(&quot;enable.idempotence&quot;, &quot;true&quot;);"><pre class="notranslate"><code>kafka::Properties props;
props.put("bootstrap.servers", brokers);
props.put("enable.idempotence", "true");
</code></pre></div>
</li>
</ol>
<ul dir="auto">
<li>Note: <code>bootstrap.servers</code> is the only mandatory property for a Kafka client</li>
</ul>
<div class="markdown-heading" dir="auto"><h2 class="heading-element" dir="auto">KafkaProducer</h2><a id="user-content-kafkaproducer" class="anchor" aria-label="Permalink: KafkaProducer" href="#kafkaproducer"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><a href="http://opensource.morganstanley.com/modern-cpp-kafka/doxygen/classKAFKA__API_1_1clients_1_1producer_1_1KafkaProducer.html" rel="nofollow">kafka::clients::producer::KafkaProducer Class Reference</a></p>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">A Simple Example</h3><a id="user-content-a-simple-example" class="anchor" aria-label="Permalink: A Simple Example" href="#a-simple-example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Here's a very simple example to see how to send a message with a <code>KafkaProducer</code>.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="#include &lt;kafka/KafkaProducer.h&gt;

#include &lt;cstdlib&gt;
#include &lt;iostream&gt;
#include &lt;string&gt;


int main()
{
    using namespace kafka;
    using namespace kafka::clients::producer;

    // E.g. KAFKA_BROKER_LIST: &quot;192.168.0.1:9092,192.168.0.2:9092,192.168.0.3:9092&quot;
    const std::string brokers = getenv(&quot;KAFKA_BROKER_LIST&quot;); // NOLINT
    const Topic topic = getenv(&quot;TOPIC_FOR_TEST&quot;);            // NOLINT

    // Prepare the configuration
    const Properties props({{&quot;bootstrap.servers&quot;, brokers}});

    // Create a producer
    KafkaProducer producer(props);

    // Prepare a message
    std::cout &lt;&lt; &quot;Type message value and hit enter to produce message...&quot; &lt;&lt; std::endl;
    std::string line;
    std::getline(std::cin, line);

    ProducerRecord record(topic, NullKey, Value(line.c_str(), line.size()));

    // Prepare delivery callback
    auto deliveryCb = [](const RecordMetadata&amp; metadata, const Error&amp; error) {
        if (!error) {
            std::cout &lt;&lt; &quot;Message delivered: &quot; &lt;&lt; metadata.toString() &lt;&lt; std::endl;
        } else {
            std::cerr &lt;&lt; &quot;Message failed to be delivered: &quot; &lt;&lt; error.message() &lt;&lt; std::endl;
        }
    };

    // Send a message
    producer.send(record, deliveryCb);

    // Close the producer explicitly(or not, since RAII will take care of it)
    producer.close();
}"><pre class="notranslate"><code>#include &lt;kafka/KafkaProducer.h&gt;

#include &lt;cstdlib&gt;
#include &lt;iostream&gt;
#include &lt;string&gt;


int main()
{
    using namespace kafka;
    using namespace kafka::clients::producer;

    // E.g. KAFKA_BROKER_LIST: "192.168.0.1:9092,192.168.0.2:9092,192.168.0.3:9092"
    const std::string brokers = getenv("KAFKA_BROKER_LIST"); // NOLINT
    const Topic topic = getenv("TOPIC_FOR_TEST");            // NOLINT

    // Prepare the configuration
    const Properties props({{"bootstrap.servers", brokers}});

    // Create a producer
    KafkaProducer producer(props);

    // Prepare a message
    std::cout &lt;&lt; "Type message value and hit enter to produce message..." &lt;&lt; std::endl;
    std::string line;
    std::getline(std::cin, line);

    ProducerRecord record(topic, NullKey, Value(line.c_str(), line.size()));

    // Prepare delivery callback
    auto deliveryCb = [](const RecordMetadata&amp; metadata, const Error&amp; error) {
        if (!error) {
            std::cout &lt;&lt; "Message delivered: " &lt;&lt; metadata.toString() &lt;&lt; std::endl;
        } else {
            std::cerr &lt;&lt; "Message failed to be delivered: " &lt;&lt; error.message() &lt;&lt; std::endl;
        }
    };

    // Send a message
    producer.send(record, deliveryCb);

    // Close the producer explicitly(or not, since RAII will take care of it)
    producer.close();
}
</code></pre></div>
<div class="markdown-heading" dir="auto"><h4 class="heading-element" dir="auto">Notes</h4><a id="user-content-notes" class="anchor" aria-label="Permalink: Notes" href="#notes"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">The <code>send()</code> is an unblocked operation unless the message buffering queue is full.</p>
</li>
<li>
<p dir="auto">Make sure the memory block for <code>ProducerRecord</code>'s <code>key</code> is valid until the <code>send</code> is called.</p>
</li>
<li>
<p dir="auto">Make sure the memory block for <code>ProducerRecord</code>'s <code>value</code> is valid until the message delivery callback is called (unless the <code>send</code> is with option <code>KafkaProducer::SendOption::ToCopyRecordValue</code>).</p>
</li>
<li>
<p dir="auto">It's guaranteed that the message delivery callback would be triggered anyway after <code>send</code>, -- a producer would even be waiting for it before close.</p>
</li>
<li>
<p dir="auto">At the end, we could close Kafka client (i.e. <code>KafkaProducer</code> or <code>KafkaConsumer</code>) explicitly, or just leave it to the destructor.</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">The Lifecycle of the Message</h3><a id="user-content-the-lifecycle-of-the-message" class="anchor" aria-label="Permalink: The Lifecycle of the Message" href="#the-lifecycle-of-the-message"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The message for the KafkaProducer is called <code>ProducerRecord</code>, it contains <code>Topic</code>, <code>Partition</code> (optional), <code>Key</code> and <code>Value</code>. Both <code>Key</code> &amp; <code>Value</code> are <code>const_buffer</code>, and since there's no deep-copy for the <code>Value</code>, the user should make sure the memory block for the <code>Value</code> be valid, until the delivery callback has been executed.</p>
<p dir="auto">In the previous example, we don't need to worry about the lifecycle of <code>Value</code>, since the content of the <code>line</code> keeps to be available before closing the producer, and all message delivery callbacks would be triggered before finishing closing the producer.</p>
<div class="markdown-heading" dir="auto"><h4 class="heading-element" dir="auto">Example for shared_ptr</h4><a id="user-content-example-for-shared_ptr" class="anchor" aria-label="Permalink: Example for shared_ptr" href="#example-for-shared_ptr"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">A trick is capturing the shared pointer (for the memory block of <code>Value</code>) in the message delivery callback.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="    std::cout &lt;&lt; &quot;Type message value and hit enter to produce message... (empty line to quit)&quot; &lt;&lt; std::endl;

    // Get input lines and forward them to Kafka
    for (auto line = std::make_shared&lt;std::string&gt;();
         std::getline(std::cin, *line);
         line = std::make_shared&lt;std::string&gt;()) {

        // Empty line to quit
        if (line-&gt;empty()) break;

        // Prepare a message
        ProducerRecord record(topic, NullKey, Value(line-&gt;c_str(), line-&gt;size()));

        // Prepare delivery callback
        // Note: Here we capture the shared pointer of `line`, which holds the content for `record.value()`
        auto deliveryCb = [line](const RecordMetadata&amp; metadata, const Error&amp; error) {
            if (!error) {
                std::cout &lt;&lt; &quot;Message delivered: &quot; &lt;&lt; metadata.toString() &lt;&lt; std::endl;
            } else {
                std::cerr &lt;&lt; &quot;Message failed to be delivered: &quot; &lt;&lt; error.message() &lt;&lt; std::endl;
            }
        };

        // Send the message
        producer.send(record, deliveryCb);
    }"><pre class="notranslate"><code>    std::cout &lt;&lt; "Type message value and hit enter to produce message... (empty line to quit)" &lt;&lt; std::endl;

    // Get input lines and forward them to Kafka
    for (auto line = std::make_shared&lt;std::string&gt;();
         std::getline(std::cin, *line);
         line = std::make_shared&lt;std::string&gt;()) {

        // Empty line to quit
        if (line-&gt;empty()) break;

        // Prepare a message
        ProducerRecord record(topic, NullKey, Value(line-&gt;c_str(), line-&gt;size()));

        // Prepare delivery callback
        // Note: Here we capture the shared pointer of `line`, which holds the content for `record.value()`
        auto deliveryCb = [line](const RecordMetadata&amp; metadata, const Error&amp; error) {
            if (!error) {
                std::cout &lt;&lt; "Message delivered: " &lt;&lt; metadata.toString() &lt;&lt; std::endl;
            } else {
                std::cerr &lt;&lt; "Message failed to be delivered: " &lt;&lt; error.message() &lt;&lt; std::endl;
            }
        };

        // Send the message
        producer.send(record, deliveryCb);
    }
</code></pre></div>
<div class="markdown-heading" dir="auto"><h4 class="heading-element" dir="auto">Example for deep-copy</h4><a id="user-content-example-for-deep-copy" class="anchor" aria-label="Permalink: Example for deep-copy" href="#example-for-deep-copy"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The option <code>KafkaProducer::SendOption::ToCopyRecordValue</code> could be used for <code>producer.send(...)</code>, thus the memory block of <code>record.value()</code> would be copied into the internal sending buffer.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="    std::cout &lt;&lt; &quot;Type message value and hit enter to produce message... (empty line to quit)&quot; &lt;&lt; std::endl;

    // Get input lines and forward them to Kafka
    for (std::string line; std::getline(std::cin, line); ) {

        // Empty line to quit
        if (line.empty()) break;

        // Prepare a message
        ProducerRecord record(topic, NullKey, Value(line.c_str(), line.size()));

        // Prepare delivery callback
        auto deliveryCb = [](const RecordMetadata&amp; metadata, const Error&amp; error) {
            if (!error) {
                std::cout &lt;&lt; &quot;Message delivered: &quot; &lt;&lt; metadata.toString() &lt;&lt; std::endl;
            } else {
                std::cerr &lt;&lt; &quot;Message failed to be delivered: &quot; &lt;&lt; error.message() &lt;&lt; std::endl;
            }
        };

        // Send the message (deep-copy the payload)
        producer.send(record, deliveryCb, KafkaProducer::SendOption::ToCopyRecordValue);
    }"><pre class="notranslate"><code>    std::cout &lt;&lt; "Type message value and hit enter to produce message... (empty line to quit)" &lt;&lt; std::endl;

    // Get input lines and forward them to Kafka
    for (std::string line; std::getline(std::cin, line); ) {

        // Empty line to quit
        if (line.empty()) break;

        // Prepare a message
        ProducerRecord record(topic, NullKey, Value(line.c_str(), line.size()));

        // Prepare delivery callback
        auto deliveryCb = [](const RecordMetadata&amp; metadata, const Error&amp; error) {
            if (!error) {
                std::cout &lt;&lt; "Message delivered: " &lt;&lt; metadata.toString() &lt;&lt; std::endl;
            } else {
                std::cerr &lt;&lt; "Message failed to be delivered: " &lt;&lt; error.message() &lt;&lt; std::endl;
            }
        };

        // Send the message (deep-copy the payload)
        producer.send(record, deliveryCb, KafkaProducer::SendOption::ToCopyRecordValue);
    }
</code></pre></div>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">Embed More Info in a <code>ProducerRecord</code></h3><a id="user-content-embed-more-info-in-a-producerrecord" class="anchor" aria-label="Permalink: Embed More Info in a ProducerRecord" href="#embed-more-info-in-a-producerrecord"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Besides the <code>payload</code> (i.e. <code>value()</code>), a <code>ProducerRecord</code> could also put extra info in its <code>key()</code> &amp; <code>headers()</code>.</p>
<p dir="auto"><code>Headers</code> is a vector of <code>Header</code> which contains <code>kafka::Header::Key</code> (i.e. <code>std::string</code>) and <code>kafka::Header::Value</code> (i.e. <code>const_buffer</code>).</p>
<div class="markdown-heading" dir="auto"><h4 class="heading-element" dir="auto">Example</h4><a id="user-content-example" class="anchor" aria-label="Permalink: Example" href="#example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="    const kafka::Topic     topic     = &quot;someTopic&quot;;
    const kafka::Partition partition = 0;

    const std::string key       = &quot;some key&quot;;
    const std::string value     = &quot;some payload&quot;;

    const std::string category  = &quot;categoryA&quot;;
    const std::size_t sessionId = 1;

    {
        kafka::clients::producer::ProducerRecord record(topic,
                                                        partition,
                                                        kafka::Key{key.c_str(), key.size()},
                                                        kafka::Value{value.c_str(), value.size()});

        record.headers() = {{
            kafka::Header{kafka::Header::Key{&quot;Category&quot;},  kafka::Header::Value{category.c_str(), category.size()}},
            kafka::Header{kafka::Header::Key{&quot;SessionId&quot;}, kafka::Header::Value{&amp;sessionId, sizeof(sessionId)}}
        }};

        std::cout &lt;&lt; &quot;ProducerRecord: &quot; &lt;&lt; record.toString() &lt;&lt; std::endl;
    }"><pre class="notranslate"><code>    const kafka::Topic     topic     = "someTopic";
    const kafka::Partition partition = 0;

    const std::string key       = "some key";
    const std::string value     = "some payload";

    const std::string category  = "categoryA";
    const std::size_t sessionId = 1;

    {
        kafka::clients::producer::ProducerRecord record(topic,
                                                        partition,
                                                        kafka::Key{key.c_str(), key.size()},
                                                        kafka::Value{value.c_str(), value.size()});

        record.headers() = {{
            kafka::Header{kafka::Header::Key{"Category"},  kafka::Header::Value{category.c_str(), category.size()}},
            kafka::Header{kafka::Header::Key{"SessionId"}, kafka::Header::Value{&amp;sessionId, sizeof(sessionId)}}
        }};

        std::cout &lt;&lt; "ProducerRecord: " &lt;&lt; record.toString() &lt;&lt; std::endl;
    }
</code></pre></div>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">About <code>enable.manual.events.poll</code></h3><a id="user-content-about-enablemanualeventspoll" class="anchor" aria-label="Permalink: About enable.manual.events.poll" href="#about-enablemanualeventspoll"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">By default, <code>KafkaProducer</code> would be constructed with <code>enable.manual.events.poll=false</code> configuration.
That means, a background thread would be created, which keeps polling the events (thus calls the message delivery callbacks)</p>
<p dir="auto">Here we have another choice, -- using <code>enable.manual.events.poll=true</code>, thus the MessageDelivery callbacks would be called within member function <code>pollEvents()</code>.</p>
<ul dir="auto">
<li>Note: in this case, the send() will be an unblocked operation even if the message buffering queue is full, -- it would throw an exception (or return an error code with the input reference parameter), instead of blocking there.</li>
</ul>
<div class="markdown-heading" dir="auto"><h4 class="heading-element" dir="auto">Example</h4><a id="user-content-example-1" class="anchor" aria-label="Permalink: Example" href="#example-1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="    // Prepare the configuration (with &quot;enable.manual.events.poll=true&quot;)
    const Properties props({{&quot;bootstrap.servers&quot;,         {brokers}},
                            {&quot;enable.manual.events.poll&quot;, {&quot;true&quot; }}});

    // Create a producer
    KafkaProducer producer(props);

    std::cout &lt;&lt; &quot;Type message value and hit enter to produce message... (empty line to finish)&quot; &lt;&lt; std::endl;

    // Get all input lines
    std::list&lt;std::shared_ptr&lt;std::string&gt;&gt; messages;
    for (auto line = std::make_shared&lt;std::string&gt;(); std::getline(std::cin, *line) &amp;&amp; !line-&gt;empty();) {
        messages.emplace_back(line);
    }

    while (!messages.empty()) {
        // Pop out a message to be sent
        auto payload = messages.front();
        messages.pop_front();

        // Prepare the message
        ProducerRecord record(topic, NullKey, Value(payload-&gt;c_str(), payload-&gt;size()));

        // Prepare the delivery callback
        // Note: if fails, the message will be pushed back to the sending queue, and then retries later
        auto deliveryCb = [payload, &amp;messages](const RecordMetadata&amp; metadata, const Error&amp; error) {
            if (!error) {
                std::cout &lt;&lt; &quot;Message delivered: &quot; &lt;&lt; metadata.toString() &lt;&lt; std::endl;
            } else {
                std::cerr &lt;&lt; &quot;Message failed to be delivered: &quot; &lt;&lt; error.message() &lt;&lt; &quot;, will be retried later&quot; &lt;&lt; std::endl;
                messages.emplace_back(payload);
            }
        };

        // Send the message
        producer.send(record, deliveryCb);

        // Poll events (e.g. message delivery callback)
        producer.pollEvents(std::chrono::milliseconds(0));
    }"><pre class="notranslate"><code>    // Prepare the configuration (with "enable.manual.events.poll=true")
    const Properties props({{"bootstrap.servers",         {brokers}},
                            {"enable.manual.events.poll", {"true" }}});

    // Create a producer
    KafkaProducer producer(props);

    std::cout &lt;&lt; "Type message value and hit enter to produce message... (empty line to finish)" &lt;&lt; std::endl;

    // Get all input lines
    std::list&lt;std::shared_ptr&lt;std::string&gt;&gt; messages;
    for (auto line = std::make_shared&lt;std::string&gt;(); std::getline(std::cin, *line) &amp;&amp; !line-&gt;empty();) {
        messages.emplace_back(line);
    }

    while (!messages.empty()) {
        // Pop out a message to be sent
        auto payload = messages.front();
        messages.pop_front();

        // Prepare the message
        ProducerRecord record(topic, NullKey, Value(payload-&gt;c_str(), payload-&gt;size()));

        // Prepare the delivery callback
        // Note: if fails, the message will be pushed back to the sending queue, and then retries later
        auto deliveryCb = [payload, &amp;messages](const RecordMetadata&amp; metadata, const Error&amp; error) {
            if (!error) {
                std::cout &lt;&lt; "Message delivered: " &lt;&lt; metadata.toString() &lt;&lt; std::endl;
            } else {
                std::cerr &lt;&lt; "Message failed to be delivered: " &lt;&lt; error.message() &lt;&lt; ", will be retried later" &lt;&lt; std::endl;
                messages.emplace_back(payload);
            }
        };

        // Send the message
        producer.send(record, deliveryCb);

        // Poll events (e.g. message delivery callback)
        producer.pollEvents(std::chrono::milliseconds(0));
    }
</code></pre></div>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">Error Handling</h3><a id="user-content-error-handling" class="anchor" aria-label="Permalink: Error Handling" href="#error-handling"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><a href="http://opensource.morganstanley.com/modern-cpp-kafka/doxygen/classKAFKA__API_1_1Error.html" rel="nofollow"><code>kafka::Error</code></a> might occur at different places while sending a message,</p>
<ul dir="auto">
<li>
<p dir="auto">A <a href="http://opensource.morganstanley.com/modern-cpp-kafka/doxygen/classKAFKA__API_1_1KafkaException.html" rel="nofollow"><code>kafka::KafkaException</code></a> would be triggered if <code>KafkaProducer</code> fails to call the <code>send</code> operation.</p>
</li>
<li>
<p dir="auto">Delivery <a href="http://opensource.morganstanley.com/modern-cpp-kafka/doxygen/classKAFKA__API_1_1Error.html" rel="nofollow"><code>kafka::Error</code></a> could be fetched via the delivery-callback.</p>
</li>
<li>
<p dir="auto">The <code>kafka::Error::value()</code> for failures</p>
<ul dir="auto">
<li>
<p dir="auto">Local errors</p>
<ul dir="auto">
<li>
<p dir="auto"><code>RD_KAFKA_RESP_ERR__UNKNOWN_TOPIC</code>      -- The topic doesn't exist</p>
</li>
<li>
<p dir="auto"><code>RD_KAFKA_RESP_ERR__UNKNOWN_PARTITION</code>  -- The partition doesn't exist</p>
</li>
<li>
<p dir="auto"><code>RD_KAFKA_RESP_ERR__INVALID_ARG</code>        -- Invalid topic (topic is null or the length is too long (&gt;512))</p>
</li>
<li>
<p dir="auto"><code>RD_KAFKA_RESP_ERR__MSG_TIMED_OUT</code>      -- No ack received within the time limit</p>
</li>
<li>
<p dir="auto"><code>RD_KAFKA_RESP_ERR_INVALID_MSG_SIZE</code>    -- The message size conflicts with local configuration <code>message.max.bytes</code></p>
</li>
</ul>
</li>
<li>
<p dir="auto">Broker errors</p>
<ul dir="auto">
<li>
<p dir="auto"><a href="https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-ErrorCodes" rel="nofollow">Error Codes</a></p>
</li>
<li>
<p dir="auto">Typical errors are</p>
<ul dir="auto">
<li>
<p dir="auto">Invalid message: <code>RD_KAFKA_RESP_ERR_CORRUPT_MESSAGE</code>, <code>RD_KAFKA_RESP_ERR_MSG_SIZE_TOO_LARGE</code>, <code>RD_KAFKA_RESP_ERR_INVALID_REQUIRED_ACKS</code>, <code>RD_KAFKA_RESP_ERR_UNSUPPORTED_FOR_MESSAGE_FORMAT</code>, <code>RD_KAFKA_RESP_ERR_RECORD_LIST_TOO_LARGE</code>.</p>
</li>
<li>
<p dir="auto">Topic/Partition not exist: <code>RD_KAFKA_RESP_ERR_UNKNOWN_TOPIC_OR_PART</code>, -- automatic topic creation is disabled on the broker or the application is specifying a partition that does not exist.</p>
</li>
<li>
<p dir="auto">Authorization failure: <code>RD_KAFKA_RESP_ERR_TOPIC_AUTHORIZATION_FAILED</code>, <code>RD_KAFKA_RESP_ERR_CLUSTER_AUTHORIZATION_FAILED</code></p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">Idempotent Producer</h3><a id="user-content-idempotent-producer" class="anchor" aria-label="Permalink: Idempotent Producer" href="#idempotent-producer"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The <code>enable.idempotence=true</code> configuration is highly RECOMMENDED.</p>
<div class="markdown-heading" dir="auto"><h4 class="heading-element" dir="auto">Example</h4><a id="user-content-example-2" class="anchor" aria-label="Permalink: Example" href="#example-2"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="        kafka::Properties props;
        props.put(&quot;bootstrap.servers&quot;, brokers);
        props.put(&quot;enable.idempotence&quot;, &quot;true&quot;);

        // Create an idempotent producer
        kafka::clients::producer::KafkaProducer producer(props);"><pre class="notranslate"><code>        kafka::Properties props;
        props.put("bootstrap.servers", brokers);
        props.put("enable.idempotence", "true");

        // Create an idempotent producer
        kafka::clients::producer::KafkaProducer producer(props);
</code></pre></div>
<ul dir="auto">
<li>Note: please refer to the <a href="https://github.com/confluentinc/librdkafka/blob/master/INTRODUCTION.md#idempotent-producer">document from <strong>librdkafka</strong></a> for more details.</li>
</ul>
<div class="markdown-heading" dir="auto"><h2 class="heading-element" dir="auto">Kafka Consumer</h2><a id="user-content-kafka-consumer" class="anchor" aria-label="Permalink: Kafka Consumer" href="#kafka-consumer"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><a href="http://opensource.morganstanley.com/modern-cpp-kafka/doxygen/classKAFKA__API_1_1clients_1_1consumer_1_1KafkaConsumer.html" rel="nofollow">kafka::clients::consumer::KafkaConsumer Class Reference</a></p>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">A Simple Example</h3><a id="user-content-a-simple-example-1" class="anchor" aria-label="Permalink: A Simple Example" href="#a-simple-example-1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="#include &lt;kafka/KafkaConsumer.h&gt;

#include &lt;cstdlib&gt;
#include &lt;iostream&gt;
#include &lt;signal.h&gt;
#include &lt;string&gt;

std::atomic_bool running = {true};

void stopRunning(int sig) {
    if (sig != SIGINT) return;

    if (running) {
        running = false;
    } else {
        // Restore the signal handler, -- to avoid stuck with this handler
        signal(SIGINT, SIG_IGN); // NOLINT
    }
}

int main()
{
    using namespace kafka;
    using namespace kafka::clients::consumer;

    // Use Ctrl-C to terminate the program
    signal(SIGINT, stopRunning);    // NOLINT

    // E.g. KAFKA_BROKER_LIST: &quot;192.168.0.1:9092,192.168.0.2:9092,192.168.0.3:9092&quot;
    const std::string brokers = getenv(&quot;KAFKA_BROKER_LIST&quot;); // NOLINT
    const Topic topic = getenv(&quot;TOPIC_FOR_TEST&quot;);            // NOLINT

    // Prepare the configuration
    const Properties props({{&quot;bootstrap.servers&quot;, {brokers}}});

    // Create a consumer instance
    KafkaConsumer consumer(props);

    // Subscribe to topics
    consumer.subscribe({topic});

    while (running) {
        // Poll messages from Kafka brokers
        auto records = consumer.poll(std::chrono::milliseconds(100));

        for (const auto&amp; record: records) {
            if (!record.error()) {
                std::cout &lt;&lt; &quot;Got a new message...&quot; &lt;&lt; std::endl;
                std::cout &lt;&lt; &quot;    Topic    : &quot; &lt;&lt; record.topic() &lt;&lt; std::endl;
                std::cout &lt;&lt; &quot;    Partition: &quot; &lt;&lt; record.partition() &lt;&lt; std::endl;
                std::cout &lt;&lt; &quot;    Offset   : &quot; &lt;&lt; record.offset() &lt;&lt; std::endl;
                std::cout &lt;&lt; &quot;    Timestamp: &quot; &lt;&lt; record.timestamp().toString() &lt;&lt; std::endl;
                std::cout &lt;&lt; &quot;    Headers  : &quot; &lt;&lt; toString(record.headers()) &lt;&lt; std::endl;
                std::cout &lt;&lt; &quot;    Key   [&quot; &lt;&lt; record.key().toString() &lt;&lt; &quot;]&quot; &lt;&lt; std::endl;
                std::cout &lt;&lt; &quot;    Value [&quot; &lt;&lt; record.value().toString() &lt;&lt; &quot;]&quot; &lt;&lt; std::endl;
            } else {
                std::cerr &lt;&lt; record.toString() &lt;&lt; std::endl;
            }
        }
    }

    // No explicit close is needed, RAII will take care of it
    consumer.close();
}"><pre class="notranslate"><code>#include &lt;kafka/KafkaConsumer.h&gt;

#include &lt;cstdlib&gt;
#include &lt;iostream&gt;
#include &lt;signal.h&gt;
#include &lt;string&gt;

std::atomic_bool running = {true};

void stopRunning(int sig) {
    if (sig != SIGINT) return;

    if (running) {
        running = false;
    } else {
        // Restore the signal handler, -- to avoid stuck with this handler
        signal(SIGINT, SIG_IGN); // NOLINT
    }
}

int main()
{
    using namespace kafka;
    using namespace kafka::clients::consumer;

    // Use Ctrl-C to terminate the program
    signal(SIGINT, stopRunning);    // NOLINT

    // E.g. KAFKA_BROKER_LIST: "192.168.0.1:9092,192.168.0.2:9092,192.168.0.3:9092"
    const std::string brokers = getenv("KAFKA_BROKER_LIST"); // NOLINT
    const Topic topic = getenv("TOPIC_FOR_TEST");            // NOLINT

    // Prepare the configuration
    const Properties props({{"bootstrap.servers", {brokers}}});

    // Create a consumer instance
    KafkaConsumer consumer(props);

    // Subscribe to topics
    consumer.subscribe({topic});

    while (running) {
        // Poll messages from Kafka brokers
        auto records = consumer.poll(std::chrono::milliseconds(100));

        for (const auto&amp; record: records) {
            if (!record.error()) {
                std::cout &lt;&lt; "Got a new message..." &lt;&lt; std::endl;
                std::cout &lt;&lt; "    Topic    : " &lt;&lt; record.topic() &lt;&lt; std::endl;
                std::cout &lt;&lt; "    Partition: " &lt;&lt; record.partition() &lt;&lt; std::endl;
                std::cout &lt;&lt; "    Offset   : " &lt;&lt; record.offset() &lt;&lt; std::endl;
                std::cout &lt;&lt; "    Timestamp: " &lt;&lt; record.timestamp().toString() &lt;&lt; std::endl;
                std::cout &lt;&lt; "    Headers  : " &lt;&lt; toString(record.headers()) &lt;&lt; std::endl;
                std::cout &lt;&lt; "    Key   [" &lt;&lt; record.key().toString() &lt;&lt; "]" &lt;&lt; std::endl;
                std::cout &lt;&lt; "    Value [" &lt;&lt; record.value().toString() &lt;&lt; "]" &lt;&lt; std::endl;
            } else {
                std::cerr &lt;&lt; record.toString() &lt;&lt; std::endl;
            }
        }
    }

    // No explicit close is needed, RAII will take care of it
    consumer.close();
}
</code></pre></div>
<ul dir="auto">
<li>
<p dir="auto">By default, the <code>KafkaConsumer</code> is constructed with property <code>enable.auto.commit=true</code></p>
<ul dir="auto">
<li>
<p dir="auto">It means it will automatically commit previously polled offsets on each poll (and the final close) operations.</p>
<ul dir="auto">
<li>Note: the internal offset commit is asynchronous, which is not guaranteed to succeed. Since the operation is supposed to be triggered (again) at a later time (within each <code>poll</code>), thus the occasional failure doesn't matter.</li>
</ul>
</li>
</ul>
</li>
<li>
<p dir="auto"><code>subscribe</code> could take a topic list. It's a block operation, and would wait for the consumer to get partitions assigned.</p>
</li>
<li>
<p dir="auto"><code>poll</code> must be called periodically, thus to trigger kinds of callback handling internally. In practice, it could be put in a <code>while loop</code>.</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">Rebalance events</h3><a id="user-content-rebalance-events" class="anchor" aria-label="Permalink: Rebalance events" href="#rebalance-events"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The <code>KafkaConsumer</code> could specify the <code>RebalanceCallback</code> while it subscribes the topics, and the callback will be triggered while partitions are assigned or revoked.</p>
<div class="markdown-heading" dir="auto"><h4 class="heading-element" dir="auto">Example</h4><a id="user-content-example-3" class="anchor" aria-label="Permalink: Example" href="#example-3"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="    // The consumer would read all messages from the topic and then quit.

    // Prepare the configuration
    const Properties props({{&quot;bootstrap.servers&quot;,    {brokers}},
                            // Emit RD_KAFKA_RESP_ERR__PARTITION_EOF event
                            // whenever the consumer reaches the end of a partition.
                            {&quot;enable.partition.eof&quot;, {&quot;true&quot;}},
                            // Action to take when there is no initial offset in offset store
                            // it means the consumer would read from the very beginning
                            {&quot;auto.offset.reset&quot;,    {&quot;earliest&quot;}}});

    // Create a consumer instance
    KafkaConsumer consumer(props);

    // Prepare the rebalance callbacks
    std::atomic&lt;std::size_t&gt; assignedPartitions{};
    auto rebalanceCb = [&amp;assignedPartitions](kafka::clients::consumer::RebalanceEventType et, const kafka::TopicPartitions&amp; tps) {
                           if (et == kafka::clients::consumer::RebalanceEventType::PartitionsAssigned) {
                               assignedPartitions += tps.size();
                               std::cout &lt;&lt; &quot;Assigned partitions: &quot; &lt;&lt; kafka::toString(tps) &lt;&lt; std::endl;
                           } else {
                               assignedPartitions -= tps.size();
                               std::cout &lt;&lt; &quot;Revoked partitions: &quot; &lt;&lt; kafka::toString(tps) &lt;&lt; std::endl;
                           }
                       };

    // Subscribe to topics with rebalance callback
    consumer.subscribe({topic}, rebalanceCb);

    TopicPartitions finishedPartitions;
    while (finishedPartitions.size() != assignedPartitions.load()) {
        // Poll messages from Kafka brokers
        auto records = consumer.poll(std::chrono::milliseconds(100));

        for (const auto&amp; record: records) {
            if (!record.error()) {
                std::cerr &lt;&lt; record.toString() &lt;&lt; std::endl;
            } else {
                if (record.error().value() == RD_KAFKA_RESP_ERR__PARTITION_EOF) {
                    // Record the partition which has been reached the end
                    finishedPartitions.emplace(record.topic(), record.partition());
                } else {
                    std::cerr &lt;&lt; record.toString() &lt;&lt; std::endl;
                }
            }
        }
    }"><pre class="notranslate"><code>    // The consumer would read all messages from the topic and then quit.

    // Prepare the configuration
    const Properties props({{"bootstrap.servers",    {brokers}},
                            // Emit RD_KAFKA_RESP_ERR__PARTITION_EOF event
                            // whenever the consumer reaches the end of a partition.
                            {"enable.partition.eof", {"true"}},
                            // Action to take when there is no initial offset in offset store
                            // it means the consumer would read from the very beginning
                            {"auto.offset.reset",    {"earliest"}}});

    // Create a consumer instance
    KafkaConsumer consumer(props);

    // Prepare the rebalance callbacks
    std::atomic&lt;std::size_t&gt; assignedPartitions{};
    auto rebalanceCb = [&amp;assignedPartitions](kafka::clients::consumer::RebalanceEventType et, const kafka::TopicPartitions&amp; tps) {
                           if (et == kafka::clients::consumer::RebalanceEventType::PartitionsAssigned) {
                               assignedPartitions += tps.size();
                               std::cout &lt;&lt; "Assigned partitions: " &lt;&lt; kafka::toString(tps) &lt;&lt; std::endl;
                           } else {
                               assignedPartitions -= tps.size();
                               std::cout &lt;&lt; "Revoked partitions: " &lt;&lt; kafka::toString(tps) &lt;&lt; std::endl;
                           }
                       };

    // Subscribe to topics with rebalance callback
    consumer.subscribe({topic}, rebalanceCb);

    TopicPartitions finishedPartitions;
    while (finishedPartitions.size() != assignedPartitions.load()) {
        // Poll messages from Kafka brokers
        auto records = consumer.poll(std::chrono::milliseconds(100));

        for (const auto&amp; record: records) {
            if (!record.error()) {
                std::cerr &lt;&lt; record.toString() &lt;&lt; std::endl;
            } else {
                if (record.error().value() == RD_KAFKA_RESP_ERR__PARTITION_EOF) {
                    // Record the partition which has been reached the end
                    finishedPartitions.emplace(record.topic(), record.partition());
                } else {
                    std::cerr &lt;&lt; record.toString() &lt;&lt; std::endl;
                }
            }
        }
    }
</code></pre></div>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">To Commit Offset Manually</h3><a id="user-content-to-commit-offset-manually" class="anchor" aria-label="Permalink: To Commit Offset Manually" href="#to-commit-offset-manually"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Once the KafkaConsumer is configured with <code>enable.auto.commit=false</code>, the user has to find out the right places to call <code>commitSync(...)</code>/<code>commitAsync(...)</code>.</p>
<div class="markdown-heading" dir="auto"><h4 class="heading-element" dir="auto">Example</h4><a id="user-content-example-4" class="anchor" aria-label="Permalink: Example" href="#example-4"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="    // Prepare the configuration
    Properties props({{&quot;bootstrap.servers&quot;, {brokers}}});
    props.put(&quot;enable.auto.commit&quot;, &quot;false&quot;);

    // Create a consumer instance
    KafkaConsumer consumer(props);

    // Subscribe to topics
    consumer.subscribe({topic});

    while (running) {
        auto records = consumer.poll(std::chrono::milliseconds(100));

        for (const auto&amp; record: records) {
            std::cout &lt;&lt; record.toString() &lt;&lt; std::endl;
        }

        if (!records.empty()) {
            consumer.commitAsync();
        }
    }

    consumer.commitSync();

    // No explicit close is needed, RAII will take care of it
    // consumer.close();"><pre class="notranslate"><code>    // Prepare the configuration
    Properties props({{"bootstrap.servers", {brokers}}});
    props.put("enable.auto.commit", "false");

    // Create a consumer instance
    KafkaConsumer consumer(props);

    // Subscribe to topics
    consumer.subscribe({topic});

    while (running) {
        auto records = consumer.poll(std::chrono::milliseconds(100));

        for (const auto&amp; record: records) {
            std::cout &lt;&lt; record.toString() &lt;&lt; std::endl;
        }

        if (!records.empty()) {
            consumer.commitAsync();
        }
    }

    consumer.commitSync();

    // No explicit close is needed, RAII will take care of it
    // consumer.close();
</code></pre></div>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">Error Handling</h3><a id="user-content-error-handling-1" class="anchor" aria-label="Permalink: Error Handling" href="#error-handling-1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">Normally, <a href="http://opensource.morganstanley.com/modern-cpp-kafka/doxygen/classKAFKA__API_1_1KafkaException.html" rel="nofollow"><code>kafka::KafkaException</code></a> will be thrown if an operation fails.</p>
</li>
<li>
<p dir="auto">But if the <code>poll</code> operation fails, the <a href="http://opensource.morganstanley.com/modern-cpp-kafka/doxygen/classKAFKA__API_1_1Error.html" rel="nofollow"><code>kafka::Error</code></a> would be embedded in the <a href="http://opensource.morganstanley.com/modern-cpp-kafka/doxygen/classKAFKA__API_1_1clients_1_1consumer_1_1ConsumerRecord.html" rel="nofollow"><code>kafka::clients::consumer::ConsumerRecord</code></a>.</p>
</li>
<li>
<p dir="auto">There're 2 cases for the <code>kafka::Error::value()</code></p>
<ul dir="auto">
<li>
<p dir="auto">Success</p>
<ul dir="auto">
<li>
<p dir="auto"><code>RD_KAFKA_RESP_ERR__NO_ERROR</code> (<code>0</code>), -- got a message successfully</p>
</li>
<li>
<p dir="auto"><code>RD_KAFKA_RESP_ERR__PARTITION_EOF</code> (<code>-191</code>), -- reached the end of a partition (no message got)</p>
</li>
</ul>
</li>
<li>
<p dir="auto">Failure</p>
<ul dir="auto">
<li><a href="https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-ErrorCodes" rel="nofollow">Error Codes</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h2 class="heading-element" dir="auto">Callbacks for KafkaClient</h2><a id="user-content-callbacks-for-kafkaclient" class="anchor" aria-label="Permalink: Callbacks for KafkaClient" href="#callbacks-for-kafkaclient"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">We're free to set callbacks in <code>Properties</code> with a <code>kafka::clients::ErrorCallback</code>, <code>kafka::clients::LogCallback</code>, or <code>kafka::clients::StatsCallback</code>.</p>
<div class="markdown-heading" dir="auto"><h4 class="heading-element" dir="auto">Example</h4><a id="user-content-example-5" class="anchor" aria-label="Permalink: Example" href="#example-5"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="    // Prepare the configuration
    Properties props({{&quot;bootstrap.servers&quot;, {brokers}}});

    // To print out the error
    props.put(&quot;error_cb&quot;, [](const kafka::Error&amp; error) {
                              // https://en.wikipedia.org/wiki/ANSI_escape_code
                              std::cerr &lt;&lt; &quot;\033[1;31m&quot; &lt;&lt; &quot;[&quot; &lt;&lt; kafka::utility::getCurrentTime() &lt;&lt; &quot;] ==&gt; Met Error: &quot; &lt;&lt; &quot;\033[0m&quot;;
                              std::cerr &lt;&lt; &quot;\033[4;35m&quot; &lt;&lt; error.toString() &lt;&lt; &quot;\033[0m&quot; &lt;&lt; std::endl;
                          });

    // To enable the debug-level log
    props.put(&quot;log_level&quot;, &quot;7&quot;);
    props.put(&quot;debug&quot;, &quot;all&quot;);
    props.put(&quot;log_cb&quot;, [](int /*level*/, const char* /*filename*/, int /*lineno*/, const char* msg) {
                            std::cout &lt;&lt; &quot;[&quot; &lt;&lt; kafka::utility::getCurrentTime() &lt;&lt; &quot;]&quot; &lt;&lt; msg &lt;&lt; std::endl;
                        });

    // To enable the statistics dumping
    props.put(&quot;statistics.interval.ms&quot;, &quot;1000&quot;);
    props.put(&quot;stats_cb&quot;, [](const std::string&amp; jsonString) {
                              std::cout &lt;&lt; &quot;Statistics: &quot; &lt;&lt; jsonString &lt;&lt; std::endl;
                          });"><pre class="notranslate"><code>    // Prepare the configuration
    Properties props({{"bootstrap.servers", {brokers}}});

    // To print out the error
    props.put("error_cb", [](const kafka::Error&amp; error) {
                              // https://en.wikipedia.org/wiki/ANSI_escape_code
                              std::cerr &lt;&lt; "\033[1;31m" &lt;&lt; "[" &lt;&lt; kafka::utility::getCurrentTime() &lt;&lt; "] ==&gt; Met Error: " &lt;&lt; "\033[0m";
                              std::cerr &lt;&lt; "\033[4;35m" &lt;&lt; error.toString() &lt;&lt; "\033[0m" &lt;&lt; std::endl;
                          });

    // To enable the debug-level log
    props.put("log_level", "7");
    props.put("debug", "all");
    props.put("log_cb", [](int /*level*/, const char* /*filename*/, int /*lineno*/, const char* msg) {
                            std::cout &lt;&lt; "[" &lt;&lt; kafka::utility::getCurrentTime() &lt;&lt; "]" &lt;&lt; msg &lt;&lt; std::endl;
                        });

    // To enable the statistics dumping
    props.put("statistics.interval.ms", "1000");
    props.put("stats_cb", [](const std::string&amp; jsonString) {
                              std::cout &lt;&lt; "Statistics: " &lt;&lt; jsonString &lt;&lt; std::endl;
                          });
</code></pre></div>
<div class="markdown-heading" dir="auto"><h2 class="heading-element" dir="auto">Thread Model</h2><a id="user-content-thread-model" class="anchor" aria-label="Permalink: Thread Model" href="#thread-model"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">Number of Background Threads within a Kafka Client</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>N</strong> threads for the message transmission (towards <strong>N</strong> brokers).</p>
</li>
<li>
<p dir="auto"><strong>2</strong> (for <code>KafkaProducer</code>) / <strong>3</strong> (for <code>KafkaConsumer</code>) threads to handle internal operations, timers, consumer group operations, etc.</p>
</li>
<li>
<p dir="auto"><strong>1</strong> thread for (message-delivery/offset-commit) callback events polling, -- the thread only exists while the client is configured with <code>enable.manual.events.poll=false</code> (the default config)</p>
</li>
</ul>
</li>
<li>
<p dir="auto">Which Thread Handles the Callbacks</p>
<ul dir="auto">
<li>
<p dir="auto"><code>consumer::RebalanceCallback</code>: the thread which calls  <code>consumer.poll(...)</code></p>
</li>
<li>
<p dir="auto"><code>consumer::OffsetCommitCallback</code></p>
<ul dir="auto">
<li>
<p dir="auto">While <code>enable.manual.events.poll=false</code>: the thread which calls <code>consumer.pollEvents(...)</code></p>
</li>
<li>
<p dir="auto">While <code>enable.manual.events.poll=true</code>: the background (events polling) thread</p>
</li>
</ul>
</li>
<li>
<p dir="auto"><code>producer::Callback</code></p>
<ul dir="auto">
<li>
<p dir="auto">While <code>enable.manual.events.poll=false</code>: the thread which calls <code>producer.pollEvents(...)</code></p>
</li>
<li>
<p dir="auto">While <code>enable.manual.events.poll=true</code>: the background (events polling) thread</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h1 class="heading-element" dir="auto">For Developers</h1><a id="user-content-for-developers" class="anchor" aria-label="Permalink: For Developers" href="#for-developers"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div class="markdown-heading" dir="auto"><h2 class="heading-element" dir="auto">Build (for <a href="https://github.com/morganstanley/modern-cpp-kafka/tree/main/tests">tests</a>/<a href="https://github.com/morganstanley/modern-cpp-kafka/tree/main/tools">tools</a>/<a href="https://github.com/morganstanley/modern-cpp-kafka/tree/main/examples">examples</a>)</h2><a id="user-content-build-for-teststoolsexamples" class="anchor" aria-label="Permalink: Build (for tests/tools/examples)" href="#build-for-teststoolsexamples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">Specify library locations with environment variables</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Environment Variable</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>LIBRDKAFKA_INCLUDE_DIR</code></td>
<td><em><strong>librdkafka</strong></em> headers</td>
</tr>
<tr>
<td><code>LIBRDKAFKA_LIBRARY_DIR</code></td>
<td><em><strong>librdkafka</strong></em> libraries</td>
</tr>
<tr>
<td><code>GTEST_ROOT</code></td>
<td><em><strong>googletest</strong></em> headers and libraries</td>
</tr>
<tr>
<td><code>BOOST_ROOT</code></td>
<td><em><strong>boost</strong></em> headers and libraries</td>
</tr>
<tr>
<td><code>SASL_LIBRARYDIR</code>/<code>SASL_LIBRARY</code></td>
<td>[optional] for SASL connection support</td>
</tr>
<tr>
<td><code>RAPIDJSON_INCLUDE_DIRS</code></td>
<td><code>addons/KafkaMetrics.h</code> requires <em><strong>rapidjson</strong></em> headers</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</li>
<li>
<p dir="auto">Build commands</p>
<ul dir="auto">
<li>
<p dir="auto"><code>cd empty-folder-for-build</code></p>
</li>
<li>
<p dir="auto"><code>cmake path-to-project-root</code> (following options could be used with <code>-D</code>)</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Build Option</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>BUILD_OPTION_USE_TSAN=ON</code></td>
<td>Use Thread Sanitizer</td>
</tr>
<tr>
<td><code>BUILD_OPTION_USE_ASAN=ON</code></td>
<td>Use Address Sanitizer</td>
</tr>
<tr>
<td><code>BUILD_OPTION_USE_UBSAN=ON</code></td>
<td>Use Undefined Behavior Sanitizer</td>
</tr>
<tr>
<td><code>BUILD_OPTION_CLANG_TIDY=ON</code></td>
<td>Enable clang-tidy checking</td>
</tr>
<tr>
<td><code>BUILD_OPTION_GEN_DOC=ON</code></td>
<td>Generate documentation as well</td>
</tr>
<tr>
<td><code>BUILD_OPTION_DOC_ONLY=ON</code></td>
<td>Only generate documentation</td>
</tr>
<tr>
<td><code>BUILD_OPTION_GEN_COVERAGE=ON</code></td>
<td>Generate test coverage, only support by clang currently</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</li>
<li>
<p dir="auto"><code>make</code></p>
</li>
<li>
<p dir="auto"><code>make install</code> (to install <code>tools</code>)</p>
</li>
</ul>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h2 class="heading-element" dir="auto">Run Tests</h2><a id="user-content-run-tests" class="anchor" aria-label="Permalink: Run Tests" href="#run-tests"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">Kafka cluster setup</p>
<ul dir="auto">
<li>
<p dir="auto"><a href="https://kafka.apache.org/documentation/#quickstart" rel="nofollow">Quick Start For Cluster Setup</a></p>
</li>
<li>
<p dir="auto"><a href="https://github.com/morganstanley/modern-cpp-kafka/blob/main/scripts/start-local-kafka-cluster.py">Cluster Setup Scripts For Test</a></p>
</li>
<li>
<p dir="auto"><a href="doc/KafkaBrokerConfiguration.md">Kafka Broker Configuration</a></p>
</li>
</ul>
</li>
<li>
<p dir="auto">To run the binary, the test runner requires following environment variables</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Environment Variable</th>
<th>Descrioption</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>KAFKA_BROKER_LIST</code></td>
<td>The broker list for the Kafka cluster</td>
<td><code>export KAFKA_BROKER_LIST=127.0.0.1:29091,127.0.0.1:29092,127.0.0.1:29093</code></td>
</tr>
<tr>
<td><code>KAFKA_BROKER_PIDS</code></td>
<td>The broker PIDs for test runner to manipulate</td>
<td><code>export KAFKA_BROKER_PIDS=61567,61569,61571</code></td>
</tr>
<tr>
<td><code>KAFKA_CLIENT_ADDITIONAL_SETTINGS</code></td>
<td>Could be used for addtional configuration for Kafka clients</td>
<td><code>export KAFKA_CLIENT_ADDITIONAL_SETTINGS="security.protocol=SASL_PLAINTEXT;sasl.kerberos.service.name=...;sasl.kerberos.keytab=...;sasl.kerberos.principal=..."</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<ul dir="auto">
<li>
<p dir="auto">The environment variable <code>KAFKA_BROKER_LIST</code> is mandatory for integration/robustness test, which requires the Kafka cluster.</p>
</li>
<li>
<p dir="auto">The environment variable <code>KAFKA_BROKER_PIDS</code> is mandatory for robustness test, which requires the Kafka cluster and the privilege to stop/resume the brokers.</p>
</li>
</ul>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Test Type</th>
<th><code>KAFKA_BROKER_LIST</code></th>
<th><code>KAFKA_BROKER_PIDS</code></th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/morganstanley/modern-cpp-kafka/tree/main/tests/unit">tests/unit</a></td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td><a href="https://github.com/morganstanley/modern-cpp-kafka/tree/main/tests/integration">tests/integration</a></td>
<td>Required</td>
<td>-</td>
</tr>
<tr>
<td><a href="https://github.com/morganstanley/modern-cpp-kafka/tree/main/tests/robustness">tests/robustness</a></td>
<td>Required</td>
<td>Required</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</li>
</ul>
</article></div>